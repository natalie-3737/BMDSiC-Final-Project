{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "105f5069-921d-4148-b0ae-b0e5e9002ebb",
   "metadata": {},
   "source": [
    "## GWAS QC Pipeline\n",
    "- General DS issues:\n",
    "  1. Removing inaccurate data -- context dependent\n",
    "  2. Identifying outliers -- exploratory visualization\n",
    "  3. Addressing missing data -- we will work through various examples of this\n",
    "  4. Removing duplicated data -- we work through an example of this\n",
    "  5. Standardizing data formats: remove unnecessary columns, convert data types\n",
    "  6. Ensuring that your data fits the assumptions of your model\n",
    "\n",
    "---\n",
    "- Review: Specific GWAS issues:\n",
    "  1. Shared ancestry\n",
    "  2. LD: association not causation\n",
    "\n",
    "---\n",
    "\n",
    "(From BDSiC_5A)\n",
    "Each particular dataset and question will develop a pipeline to address unique challenges that arise from unique aspects of the data/question. Genomic databases are a great example of a specialized pipeline to reduce the bias of non-independence on top of the more typical missing or inaccurate data grooming: \n",
    "\n",
    "       a. removing rare or monomorphic variants - minor allele frequency\n",
    "       b. filtering missing SNPs \n",
    "       c. identifying and removing genotyping errors\n",
    "           * heterozygosity\n",
    "           * sex discrepancy\n",
    "           * removing variants that are not in Hardy-Weinberg equilibrium (which can indicate: genotyping errors, batch effects, population stratification)\n",
    "           * PCA is straightforward way to identify population stratification or batch effects\n",
    "       d. accounting for ancestry and relatedness - another way population stratification pops up! Cases and controls should be matched by ancestry to avoid confounding and, therefore, false positives. \n",
    "       e. account for false positives (you are testing millions of hypotheses simultaneously)  \n",
    "\n",
    "    * The program Plink is standard for analysis GWAS and it requires files of specific formats: bed, fam, bim files all contain slightly different information, including gneomic variants, and family relationships. Plink makes the quality control step easier (a huge challenge) with built-in functions for the above. There are python packages that wrap around Plink and multivariate analysis tools to create a seamless pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a44b81-0694-4065-8938-e920ba03456d",
   "metadata": {},
   "source": [
    "# representing the 3-D world in 2-D: Lessons of the Mercator projection\n",
    "Benefits of Mercator projection on maps: \n",
    "* Rhumb lines are straight so navigation is easier\n",
    "Cons:\n",
    "* Northern land masses look HUGE and Southern land masses look tiny\n",
    "\n",
    "More accurate: \n",
    "* https://www.discovery.com/science/AuthaGraph-World-Accurate-Map\n",
    "* Gall-Peters projection\n",
    "\n",
    "Think about Subway maps? Are they accurate representations of the cityscape or are they not (and if not, why do they exist?)\n",
    "\n",
    "* __There are ALWAYS DELIBERATE decisions that we make about what to emphasize__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c85497-6855-4f83-9e07-18ebc50f673c",
   "metadata": {},
   "source": [
    "# Data will speak for itself, when it cleans itself.\n",
    "- What is \"tidy data\"? https://vita.had.co.nz/papers/tidy-data.pdf\n",
    "- Adopting these principles when creating your own datasets will save you so much time. However, we are usually using someone else's data and they probably didn't adopt these principles.\n",
    "- Nicely bulleted principles here: https://kbroman.org/dataorg/\n",
    "\n",
    "# General Principles of Data Cleaning, Data Preparation & QC:\n",
    "* The secret shame of Data Science: Data preparation is tedious, requires context, requires coding skills, demands creativity, doesn't feel like progress :(\n",
    "* DOCUMENT, DOCUMENT, DOCUMENT your process\n",
    "  - NOT just WHAT, but WHY. You're not going to remember the justifications tomorrow, let alone in a week or month or year. Help out your future self!\n",
    "  - no one is 'good' at this, but it is crucial.\n",
    "  - Trust no-one, not even (past) yourself -- (future) self\n",
    "---\n",
    "## Fundamentals\n",
    "1. Removing inaccurate data\n",
    "2. Identifying outliers\n",
    "3. Addressing missing data\n",
    "4. Removing duplicated data\n",
    "5. Standardizing data formats (especially dates!): remove unnecessary columns, convert data types, check merged columns/rows\n",
    "6. Ensuring that your data fits the assumptions of your model\n",
    "---\n",
    "## Questions: \n",
    "1. Is this data what I expect, even when I consider things that could have gone wrong in the data collection process? What data patterns would be present, if various common things had gone wrong?\n",
    "2. Have I checked my calculations?\n",
    "3. Can I explain outliers/oddities? Context matters: these could be real, important values, or they could be artifacts, or they could be data entry mistakes. \n",
    "4. Does my process/pipeline make sense on a broad scale? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50955c52-0963-43ae-9b6d-ba02853f1e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# typical Data Cleaning stack\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,OrdinalEncoder,OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "729793e9-69f8-47af-a855-7ae94591d9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1: we will use this to see two approaches to missing data. \n",
    "# mostly follows this: https://github.com/sumony2j/Data_Cleaning_Preprocessing/blob/main/Sample_Data_Cleaning%26Preprocessing.ipynb\n",
    "\n",
    "df1 = pd.read_csv('./Simple_Data_Ex1.csv')\n",
    "df1\n",
    "# This is a small data set so we can visually see if there are any outliers or 'strange' data.\n",
    "# however, since we can't talk to the creators of this data set it is challenging to determine accuracy, outside\n",
    "# of is the data generally 'reasonable'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "029e53fe-35d5-4b4a-b392-b29830f4d894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country      0\n",
       "Age          1\n",
       "Salary       1\n",
       "Purchased    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how much missing data is there in each of these columns? \n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07c8133c-72fd-40c4-b1ec-ee8881870e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how do we want to deal with missing data? There are a handful of common strategies: \n",
    "# 0, distinctive value (-999), or mean of the column\n",
    "# ---------\n",
    "# 1. A solid choice is to replace the NaN with 0.0\n",
    "# we can do that with the SimpleImputer that we imported from the sklearn.impute module:\n",
    "Imputer1 = SimpleImputer(missing_values=np.nan,strategy='constant',fill_value=0)\n",
    "# apply the results to the df1 but only on columns that have missing data as counted in the cell above:\n",
    "#columns 1 and 2. \n",
    "df1.iloc[:,1:3]=Imputer1.fit_transform(df1.iloc[:,1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bc81d3b-8262-4a0a-87bf-9341f370b958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      0.0       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   0.0  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check in again on our dataframe\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c199525e-8157-4894-90d7-f238e0a607bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. mean of the column\n",
    "# note: since the data is no longer missing as we just modified it above to be 0, we need to \n",
    "# re-read in the data set to get this to work.\n",
    "df1b = pd.read_csv('./Simple_Data_Ex1.csv')\n",
    "df1b\n",
    "Imputer2=SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "df1b.iloc[:,1:3]=Imputer2.fit_transform(df1b.iloc[:,1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "feb463b6-f24e-4443-b71c-20b261317e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.00</td>\n",
       "      <td>72000.00</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.00</td>\n",
       "      <td>48000.00</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.00</td>\n",
       "      <td>54000.00</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.00</td>\n",
       "      <td>61000.00</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.00</td>\n",
       "      <td>63777.78</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.00</td>\n",
       "      <td>58000.00</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.78</td>\n",
       "      <td>52000.00</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.00</td>\n",
       "      <td>79000.00</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.00</td>\n",
       "      <td>83000.00</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.00</td>\n",
       "      <td>67000.00</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country    Age    Salary Purchased\n",
       "0   France  44.00  72000.00        No\n",
       "1    Spain  27.00  48000.00       Yes\n",
       "2  Germany  30.00  54000.00        No\n",
       "3    Spain  38.00  61000.00        No\n",
       "4  Germany  40.00  63777.78       Yes\n",
       "5   France  35.00  58000.00       Yes\n",
       "6    Spain  38.78  52000.00        No\n",
       "7   France  48.00  79000.00       Yes\n",
       "8  Germany  50.00  83000.00        No\n",
       "9   France  37.00  67000.00       Yes"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check in again:\n",
    "df1b\n",
    "round(df1b,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a793cc10-c955-4fdd-9156-34fb4f7b567f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>Clean &amp; quiet apt home by the park</td>\n",
       "      <td>2787</td>\n",
       "      <td>John</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>2845</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3647</td>\n",
       "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
       "      <td>4632</td>\n",
       "      <td>Elisabeth</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3831</td>\n",
       "      <td>Cozy Entire Floor of Brownstone</td>\n",
       "      <td>4869</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5022</td>\n",
       "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
       "      <td>7192</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              name  host_id  \\\n",
       "0  2539                Clean & quiet apt home by the park     2787   \n",
       "1  2595                             Skylit Midtown Castle     2845   \n",
       "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n",
       "3  3831                   Cozy Entire Floor of Brownstone     4869   \n",
       "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n",
       "\n",
       "     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
       "0         John            Brooklyn    Kensington  40.64749  -73.97237   \n",
       "1     Jennifer           Manhattan       Midtown  40.75362  -73.98377   \n",
       "2    Elisabeth           Manhattan        Harlem  40.80902  -73.94190   \n",
       "3  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976   \n",
       "4        Laura           Manhattan   East Harlem  40.79851  -73.94399   \n",
       "\n",
       "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
       "0     Private room    149               1                  9  2018-10-19   \n",
       "1  Entire home/apt    225               1                 45  2019-05-21   \n",
       "2     Private room    150               3                  0         NaN   \n",
       "3  Entire home/apt     89               1                270  2019-07-05   \n",
       "4  Entire home/apt     80              10                  9  2018-11-19   \n",
       "\n",
       "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0               0.21                               6               365  \n",
       "1               0.38                               2               355  \n",
       "2                NaN                               1               365  \n",
       "3               4.64                               1               194  \n",
       "4               0.10                               1                 0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is a second dataset. It is a bit larger than the last example. \n",
    "# taken from here: https://github.com/sumony2j/Data_Cleaning_Preprocessing/blob/main/Airbnb_NY_Data_Cleaning%26Preprocessing.ipynb\n",
    "df2 = pd.read_csv('./Data_example2.csv')\n",
    "# we just want to peak at the data - since it is large\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bde6caa2-a41e-4ac6-b0f3-fa6e1fb2473c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48895 entries, 0 to 48894\n",
      "Data columns (total 16 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   id                              48895 non-null  int64  \n",
      " 1   name                            48879 non-null  object \n",
      " 2   host_id                         48895 non-null  int64  \n",
      " 3   host_name                       48874 non-null  object \n",
      " 4   neighbourhood_group             48895 non-null  object \n",
      " 5   neighbourhood                   48895 non-null  object \n",
      " 6   latitude                        48895 non-null  float64\n",
      " 7   longitude                       48895 non-null  float64\n",
      " 8   room_type                       48895 non-null  object \n",
      " 9   price                           48895 non-null  int64  \n",
      " 10  minimum_nights                  48895 non-null  int64  \n",
      " 11  number_of_reviews               48895 non-null  int64  \n",
      " 12  last_review                     38843 non-null  object \n",
      " 13  reviews_per_month               38843 non-null  float64\n",
      " 14  calculated_host_listings_count  48895 non-null  int64  \n",
      " 15  availability_365                48895 non-null  int64  \n",
      "dtypes: float64(3), int64(7), object(6)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# how big is the data? \n",
    "df2.shape\n",
    "# Notice the difference between an attribute -- like shape -- and a method? \n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b25dc367-033f-4002-aabe-d14d8244b8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                    0\n",
       "name                                 16\n",
       "host_id                               0\n",
       "host_name                            21\n",
       "neighbourhood_group                   0\n",
       "neighbourhood                         0\n",
       "latitude                              0\n",
       "longitude                             0\n",
       "room_type                             0\n",
       "price                                 0\n",
       "minimum_nights                        0\n",
       "number_of_reviews                     0\n",
       "last_review                       10052\n",
       "reviews_per_month                 10052\n",
       "calculated_host_listings_count        0\n",
       "availability_365                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how many missing data pieces there are in each column.\n",
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02f4c574-7d2b-4259-b45f-927e999cd3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some of these columns are not useful to answer our particular question(s). \n",
    "# we can get rid of columns like so:\n",
    "df2.drop(['name','host_name','last_review'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f7f540d-c618-406b-a27e-135eb4fa5ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id  host_id neighbourhood_group neighbourhood  latitude  longitude  \\\n",
      "0  2539     2787            Brooklyn    Kensington  40.64749  -73.97237   \n",
      "1  2595     2845           Manhattan       Midtown  40.75362  -73.98377   \n",
      "2  3647     4632           Manhattan        Harlem  40.80902  -73.94190   \n",
      "3  3831     4869            Brooklyn  Clinton Hill  40.68514  -73.95976   \n",
      "4  5022     7192           Manhattan   East Harlem  40.79851  -73.94399   \n",
      "\n",
      "         room_type  price  minimum_nights  number_of_reviews  \\\n",
      "0     Private room    149               1                  9   \n",
      "1  Entire home/apt    225               1                 45   \n",
      "2     Private room    150               3                  0   \n",
      "3  Entire home/apt     89               1                270   \n",
      "4  Entire home/apt     80              10                  9   \n",
      "\n",
      "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
      "0               0.21                               6               365  \n",
      "1               0.38                               2               355  \n",
      "2                NaN                               1               365  \n",
      "3               4.64                               1               194  \n",
      "4               0.10                               1                 0  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                                    0\n",
       "host_id                               0\n",
       "neighbourhood_group                   0\n",
       "neighbourhood                         0\n",
       "latitude                              0\n",
       "longitude                             0\n",
       "room_type                             0\n",
       "price                                 0\n",
       "minimum_nights                        0\n",
       "number_of_reviews                     0\n",
       "reviews_per_month                 10052\n",
       "calculated_host_listings_count        0\n",
       "availability_365                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's peek again: \n",
    "print(df2.head())\n",
    "# see where any remaining missing data is in the columns that we decided to keep\n",
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f62bd781-dde1-45a2-8459-d8c9205b923a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>host_id</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>2787</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>2845</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3647</td>\n",
       "      <td>4632</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3831</td>\n",
       "      <td>4869</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5022</td>\n",
       "      <td>7192</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5099</td>\n",
       "      <td>7322</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Murray Hill</td>\n",
       "      <td>40.74767</td>\n",
       "      <td>-73.97500</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5121</td>\n",
       "      <td>7356</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Bedford-Stuyvesant</td>\n",
       "      <td>40.68688</td>\n",
       "      <td>-73.95596</td>\n",
       "      <td>Private room</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5178</td>\n",
       "      <td>8967</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Hell's Kitchen</td>\n",
       "      <td>40.76489</td>\n",
       "      <td>-73.98493</td>\n",
       "      <td>Private room</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>430</td>\n",
       "      <td>3.47</td>\n",
       "      <td>1</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5203</td>\n",
       "      <td>7490</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Upper West Side</td>\n",
       "      <td>40.80178</td>\n",
       "      <td>-73.96723</td>\n",
       "      <td>Private room</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5238</td>\n",
       "      <td>7549</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Chinatown</td>\n",
       "      <td>40.71344</td>\n",
       "      <td>-73.99037</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1.33</td>\n",
       "      <td>4</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5295</td>\n",
       "      <td>7702</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Upper West Side</td>\n",
       "      <td>40.80316</td>\n",
       "      <td>-73.96545</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>135</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5441</td>\n",
       "      <td>7989</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Hell's Kitchen</td>\n",
       "      <td>40.76076</td>\n",
       "      <td>-73.98867</td>\n",
       "      <td>Private room</td>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5803</td>\n",
       "      <td>9744</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>South Slope</td>\n",
       "      <td>40.66829</td>\n",
       "      <td>-73.98779</td>\n",
       "      <td>Private room</td>\n",
       "      <td>89</td>\n",
       "      <td>4</td>\n",
       "      <td>167</td>\n",
       "      <td>1.34</td>\n",
       "      <td>3</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6021</td>\n",
       "      <td>11528</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Upper West Side</td>\n",
       "      <td>40.79826</td>\n",
       "      <td>-73.96113</td>\n",
       "      <td>Private room</td>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "      <td>113</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6090</td>\n",
       "      <td>11975</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>West Village</td>\n",
       "      <td>40.73530</td>\n",
       "      <td>-74.00525</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>27</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6848</td>\n",
       "      <td>15991</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Williamsburg</td>\n",
       "      <td>40.70837</td>\n",
       "      <td>-73.95352</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>140</td>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7097</td>\n",
       "      <td>17571</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Fort Greene</td>\n",
       "      <td>40.69169</td>\n",
       "      <td>-73.97185</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>215</td>\n",
       "      <td>2</td>\n",
       "      <td>198</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7322</td>\n",
       "      <td>18946</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>40.74192</td>\n",
       "      <td>-73.99501</td>\n",
       "      <td>Private room</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7726</td>\n",
       "      <td>20950</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Crown Heights</td>\n",
       "      <td>40.67592</td>\n",
       "      <td>-73.94694</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>4.44</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7750</td>\n",
       "      <td>17985</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79685</td>\n",
       "      <td>-73.94872</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>190</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7801</td>\n",
       "      <td>21207</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Williamsburg</td>\n",
       "      <td>40.71842</td>\n",
       "      <td>-73.95718</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>299</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8024</td>\n",
       "      <td>22486</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Park Slope</td>\n",
       "      <td>40.68069</td>\n",
       "      <td>-73.97706</td>\n",
       "      <td>Private room</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>1.09</td>\n",
       "      <td>6</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8025</td>\n",
       "      <td>22486</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Park Slope</td>\n",
       "      <td>40.67989</td>\n",
       "      <td>-73.97798</td>\n",
       "      <td>Private room</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.37</td>\n",
       "      <td>6</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8110</td>\n",
       "      <td>22486</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Park Slope</td>\n",
       "      <td>40.68001</td>\n",
       "      <td>-73.97865</td>\n",
       "      <td>Private room</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>0.61</td>\n",
       "      <td>6</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8490</td>\n",
       "      <td>25183</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Bedford-Stuyvesant</td>\n",
       "      <td>40.68371</td>\n",
       "      <td>-73.94028</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>0.73</td>\n",
       "      <td>2</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  host_id neighbourhood_group       neighbourhood  latitude  \\\n",
       "0   2539     2787            Brooklyn          Kensington  40.64749   \n",
       "1   2595     2845           Manhattan             Midtown  40.75362   \n",
       "2   3647     4632           Manhattan              Harlem  40.80902   \n",
       "3   3831     4869            Brooklyn        Clinton Hill  40.68514   \n",
       "4   5022     7192           Manhattan         East Harlem  40.79851   \n",
       "5   5099     7322           Manhattan         Murray Hill  40.74767   \n",
       "6   5121     7356            Brooklyn  Bedford-Stuyvesant  40.68688   \n",
       "7   5178     8967           Manhattan      Hell's Kitchen  40.76489   \n",
       "8   5203     7490           Manhattan     Upper West Side  40.80178   \n",
       "9   5238     7549           Manhattan           Chinatown  40.71344   \n",
       "10  5295     7702           Manhattan     Upper West Side  40.80316   \n",
       "11  5441     7989           Manhattan      Hell's Kitchen  40.76076   \n",
       "12  5803     9744            Brooklyn         South Slope  40.66829   \n",
       "13  6021    11528           Manhattan     Upper West Side  40.79826   \n",
       "14  6090    11975           Manhattan        West Village  40.73530   \n",
       "15  6848    15991            Brooklyn        Williamsburg  40.70837   \n",
       "16  7097    17571            Brooklyn         Fort Greene  40.69169   \n",
       "17  7322    18946           Manhattan             Chelsea  40.74192   \n",
       "18  7726    20950            Brooklyn       Crown Heights  40.67592   \n",
       "19  7750    17985           Manhattan         East Harlem  40.79685   \n",
       "20  7801    21207            Brooklyn        Williamsburg  40.71842   \n",
       "21  8024    22486            Brooklyn          Park Slope  40.68069   \n",
       "22  8025    22486            Brooklyn          Park Slope  40.67989   \n",
       "23  8110    22486            Brooklyn          Park Slope  40.68001   \n",
       "24  8490    25183            Brooklyn  Bedford-Stuyvesant  40.68371   \n",
       "\n",
       "    longitude        room_type  price  minimum_nights  number_of_reviews  \\\n",
       "0   -73.97237     Private room    149               1                  9   \n",
       "1   -73.98377  Entire home/apt    225               1                 45   \n",
       "2   -73.94190     Private room    150               3                  0   \n",
       "3   -73.95976  Entire home/apt     89               1                270   \n",
       "4   -73.94399  Entire home/apt     80              10                  9   \n",
       "5   -73.97500  Entire home/apt    200               3                 74   \n",
       "6   -73.95596     Private room     60              45                 49   \n",
       "7   -73.98493     Private room     79               2                430   \n",
       "8   -73.96723     Private room     79               2                118   \n",
       "9   -73.99037  Entire home/apt    150               1                160   \n",
       "10  -73.96545  Entire home/apt    135               5                 53   \n",
       "11  -73.98867     Private room     85               2                188   \n",
       "12  -73.98779     Private room     89               4                167   \n",
       "13  -73.96113     Private room     85               2                113   \n",
       "14  -74.00525  Entire home/apt    120              90                 27   \n",
       "15  -73.95352  Entire home/apt    140               2                148   \n",
       "16  -73.97185  Entire home/apt    215               2                198   \n",
       "17  -73.99501     Private room    140               1                260   \n",
       "18  -73.94694  Entire home/apt     99               3                 53   \n",
       "19  -73.94872  Entire home/apt    190               7                  0   \n",
       "20  -73.95718  Entire home/apt    299               3                  9   \n",
       "21  -73.97706     Private room    130               2                130   \n",
       "22  -73.97798     Private room     80               1                 39   \n",
       "23  -73.97865     Private room    110               2                 71   \n",
       "24  -73.94028  Entire home/apt    120               2                 88   \n",
       "\n",
       "    reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0                0.21                               6               365  \n",
       "1                0.38                               2               355  \n",
       "2                0.02                               1               365  \n",
       "3                4.64                               1               194  \n",
       "4                0.10                               1                 0  \n",
       "5                0.59                               1               129  \n",
       "6                0.40                               1                 0  \n",
       "7                3.47                               1               220  \n",
       "8                0.99                               1                 0  \n",
       "9                1.33                               4               188  \n",
       "10               0.43                               1                 6  \n",
       "11               1.50                               1                39  \n",
       "12               1.34                               3               314  \n",
       "13               0.91                               1               333  \n",
       "14               0.22                               1                 0  \n",
       "15               1.20                               1                46  \n",
       "16               1.72                               1               321  \n",
       "17               2.12                               1                12  \n",
       "18               4.44                               1                21  \n",
       "19               0.02                               2               249  \n",
       "20               0.07                               1                 0  \n",
       "21               1.09                               6               347  \n",
       "22               0.37                               6               364  \n",
       "23               0.61                               6               304  \n",
       "24               0.73                               2               233  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instead of mean, median or 0.0 value, we could replace mssing values with the most frequent value\n",
    "imputer = SimpleImputer(missing_values=np.nan,strategy='most_frequent')\n",
    "# or we could use the strategy='constant',fill_value=0\n",
    "df2[['reviews_per_month']]=imputer.fit_transform(df2[['reviews_per_month']])\n",
    "df2.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea0faa99-fe6e-46ca-912a-95d17540cdae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kensington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Midtown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harlem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clinton Hill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>East Harlem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48890</th>\n",
       "      <td>Bedford-Stuyvesant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48891</th>\n",
       "      <td>Bushwick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48892</th>\n",
       "      <td>Harlem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48893</th>\n",
       "      <td>Hell's Kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48894</th>\n",
       "      <td>Hell's Kitchen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48895 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            neighbourhood\n",
       "0              Kensington\n",
       "1                 Midtown\n",
       "2                  Harlem\n",
       "3            Clinton Hill\n",
       "4             East Harlem\n",
       "...                   ...\n",
       "48890  Bedford-Stuyvesant\n",
       "48891            Bushwick\n",
       "48892              Harlem\n",
       "48893      Hell's Kitchen\n",
       "48894      Hell's Kitchen\n",
       "\n",
       "[48895 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbourhood=pd.DataFrame(df2['neighbourhood'])\n",
    "neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a41279e-783d-49a4-aedd-ebbab0df7dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Kensington', 'Midtown', 'Harlem', 'Clinton Hill', 'East Harlem',\n",
       "       'Murray Hill', 'Bedford-Stuyvesant', \"Hell's Kitchen\",\n",
       "       'Upper West Side', 'Chinatown', 'South Slope', 'West Village',\n",
       "       'Williamsburg', 'Fort Greene', 'Chelsea', 'Crown Heights',\n",
       "       'Park Slope', 'Windsor Terrace', 'Inwood', 'East Village',\n",
       "       'Greenpoint', 'Bushwick', 'Flatbush', 'Lower East Side',\n",
       "       'Prospect-Lefferts Gardens', 'Long Island City', 'Kips Bay',\n",
       "       'SoHo', 'Upper East Side', 'Prospect Heights',\n",
       "       'Washington Heights', 'Woodside', 'Brooklyn Heights',\n",
       "       'Carroll Gardens', 'Gowanus', 'Flatlands', 'Cobble Hill',\n",
       "       'Flushing', 'Boerum Hill', 'Sunnyside', 'DUMBO', 'St. George',\n",
       "       'Highbridge', 'Financial District', 'Ridgewood',\n",
       "       'Morningside Heights', 'Jamaica', 'Middle Village', 'NoHo',\n",
       "       'Ditmars Steinway', 'Flatiron District', 'Roosevelt Island',\n",
       "       'Greenwich Village', 'Little Italy', 'East Flatbush',\n",
       "       'Tompkinsville', 'Astoria', 'Clason Point', 'Eastchester',\n",
       "       'Kingsbridge', 'Two Bridges', 'Queens Village', 'Rockaway Beach',\n",
       "       'Forest Hills', 'Nolita', 'Woodlawn', 'University Heights',\n",
       "       'Gravesend', 'Gramercy', 'Allerton', 'East New York',\n",
       "       'Theater District', 'Concourse Village', 'Sheepshead Bay',\n",
       "       'Emerson Hill', 'Fort Hamilton', 'Bensonhurst', 'Tribeca',\n",
       "       'Shore Acres', 'Sunset Park', 'Concourse', 'Elmhurst',\n",
       "       'Brighton Beach', 'Jackson Heights', 'Cypress Hills', 'St. Albans',\n",
       "       'Arrochar', 'Rego Park', 'Wakefield', 'Clifton', 'Bay Ridge',\n",
       "       'Graniteville', 'Spuyten Duyvil', 'Stapleton', 'Briarwood',\n",
       "       'Ozone Park', 'Columbia St', 'Vinegar Hill', 'Mott Haven',\n",
       "       'Longwood', 'Canarsie', 'Battery Park City', 'Civic Center',\n",
       "       'East Elmhurst', 'New Springville', 'Morris Heights', 'Arverne',\n",
       "       'Cambria Heights', 'Tottenville', 'Mariners Harbor', 'Concord',\n",
       "       'Borough Park', 'Bayside', 'Downtown Brooklyn', 'Port Morris',\n",
       "       'Fieldston', 'Kew Gardens', 'Midwood', 'College Point',\n",
       "       'Mount Eden', 'City Island', 'Glendale', 'Port Richmond',\n",
       "       'Red Hook', 'Richmond Hill', 'Bellerose', 'Maspeth',\n",
       "       'Williamsbridge', 'Soundview', 'Woodhaven', 'Woodrow',\n",
       "       'Co-op City', 'Stuyvesant Town', 'Parkchester', 'North Riverdale',\n",
       "       'Dyker Heights', 'Bronxdale', 'Sea Gate', 'Riverdale',\n",
       "       'Kew Gardens Hills', 'Bay Terrace', 'Norwood', 'Claremont Village',\n",
       "       'Whitestone', 'Fordham', 'Bayswater', 'Navy Yard', 'Brownsville',\n",
       "       'Eltingville', 'Fresh Meadows', 'Mount Hope', 'Lighthouse Hill',\n",
       "       'Springfield Gardens', 'Howard Beach', 'Belle Harbor',\n",
       "       'Jamaica Estates', 'Van Nest', 'Morris Park', 'West Brighton',\n",
       "       'Far Rockaway', 'South Ozone Park', 'Tremont', 'Corona',\n",
       "       'Great Kills', 'Manhattan Beach', 'Marble Hill', 'Dongan Hills',\n",
       "       'Castleton Corners', 'East Morrisania', 'Hunts Point', 'Neponsit',\n",
       "       'Pelham Bay', 'Randall Manor', 'Throgs Neck', 'Todt Hill',\n",
       "       'West Farms', 'Silver Lake', 'Morrisania', 'Laurelton',\n",
       "       'Grymes Hill', 'Holliswood', 'Pelham Gardens', 'Belmont',\n",
       "       'Rosedale', 'Edgemere', 'New Brighton', 'Midland Beach',\n",
       "       'Baychester', 'Melrose', 'Bergen Beach', 'Richmondtown',\n",
       "       'Howland Hook', 'Schuylerville', 'Coney Island', 'New Dorp Beach',\n",
       "       \"Prince's Bay\", 'South Beach', 'Bath Beach', 'Jamaica Hills',\n",
       "       'Oakwood', 'Castle Hill', 'Hollis', 'Douglaston', 'Huguenot',\n",
       "       'Olinville', 'Edenwald', 'Grant City', 'Westerleigh',\n",
       "       'Bay Terrace, Staten Island', 'Westchester Square', 'Little Neck',\n",
       "       'Fort Wadsworth', 'Rosebank', 'Unionport', 'Mill Basin',\n",
       "       'Arden Heights', \"Bull's Head\", 'New Dorp', 'Rossville',\n",
       "       'Breezy Point', 'Willowbrook'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_unique_neighbourhoods=df2[\"neighbourhood\"].unique()\n",
    "df2_unique_neighbourhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47fd70be-a053-46af-a786-8f539ff656e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>Marital_status</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Is_graduate</th>\n",
       "      <th>Income</th>\n",
       "      <th>Loan_amount</th>\n",
       "      <th>Term_months</th>\n",
       "      <th>Credit_score</th>\n",
       "      <th>approval_status</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Hobby</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>45848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Education</td>\n",
       "      <td>Reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>45848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Education</td>\n",
       "      <td>Reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>YES</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>15325</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Education</td>\n",
       "      <td>Reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>29105</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Education</td>\n",
       "      <td>Reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>42944</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Education</td>\n",
       "      <td>Reading</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        UID Marital_status  Dependents   Is_graduate  Income  Loan_amount  \\\n",
       "0  LP001002             NO         0.0      Graduate   45848          NaN   \n",
       "1  LP001002             NO         0.0      Graduate   45848          NaN   \n",
       "2  LP001003            YES         1.0      Graduate   15325        128.0   \n",
       "3  LP001005            YES         0.0      Graduate   29105         66.0   \n",
       "4  LP001006            YES         0.0  Not Graduate   42944        120.0   \n",
       "\n",
       "   Term_months  Credit_score  approval_status   Age   Sex    Purpose    Hobby  \n",
       "0        360.0           1.0                0  40.0  Male  Education  Reading  \n",
       "1        360.0           1.0                0  40.0  Male  Education  Reading  \n",
       "2        360.0           1.0                1  22.0  Male  Education  Reading  \n",
       "3        360.0           1.0                0  27.0  Male  Education  Reading  \n",
       "4        360.0           1.0                0  36.0     F  Education  Reading  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://github.com/durgenious/loan_data_processing\n",
    "# use data loan.csv\n",
    "df3 = pd.read_csv('loan.csv')  # load 'loan.csv'\n",
    "df3.head(5) # displays first 5 records in the DataFrame\n",
    "# df3.tail(5) # displays last 5 records in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb78a2e9-5cdf-45ab-92e1-cccdff441f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 615 entries, 0 to 614\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   UID              615 non-null    object \n",
      " 1   Marital_status   613 non-null    object \n",
      " 2   Dependents       600 non-null    float64\n",
      " 3   Is_graduate      613 non-null    object \n",
      " 4   Income           615 non-null    int64  \n",
      " 5   Loan_amount      592 non-null    float64\n",
      " 6   Term_months      601 non-null    float64\n",
      " 7   Credit_score     565 non-null    float64\n",
      " 8   approval_status  615 non-null    int64  \n",
      " 9   Age              609 non-null    float64\n",
      " 10  Sex              602 non-null    object \n",
      " 11  Purpose          615 non-null    object \n",
      " 12  Hobby            615 non-null    object \n",
      "dtypes: float64(5), int64(2), object(6)\n",
      "memory usage: 62.6+ KB\n",
      "None\n",
      "------\n",
      "       Dependents        Income  Loan_amount  Term_months  Credit_score  \\\n",
      "count  600.000000  6.150000e+02   592.000000   601.000000    565.000000   \n",
      "mean     0.761667  1.896745e+05   146.412162   342.029950      0.842478   \n",
      "std      1.014847  4.031317e+06    85.587325    65.070263      0.364615   \n",
      "min      0.000000  5.001000e+03     9.000000    12.000000      0.000000   \n",
      "25%      0.000000  1.613200e+04   100.000000   360.000000      1.000000   \n",
      "50%      0.000000  2.628700e+04   128.000000   360.000000      1.000000   \n",
      "75%      2.000000  3.847700e+04   168.000000   360.000000      1.000000   \n",
      "max      3.000000  1.000000e+08   700.000000   480.000000      1.000000   \n",
      "\n",
      "       approval_status         Age  \n",
      "count       615.000000  609.000000  \n",
      "mean          0.487805   38.067323  \n",
      "std           0.500258   10.471628  \n",
      "min           0.000000  -12.000000  \n",
      "25%           0.000000   29.000000  \n",
      "50%           0.000000   37.000000  \n",
      "75%           1.000000   47.000000  \n",
      "max           1.000000   55.000000  \n",
      "~~~~~~\n",
      "(615, 13)\n",
      "**********\n",
      "UID                 0\n",
      "Marital_status      2\n",
      "Dependents         15\n",
      "Is_graduate         2\n",
      "Income              0\n",
      "Loan_amount        23\n",
      "Term_months        14\n",
      "Credit_score       50\n",
      "approval_status     0\n",
      "Age                 6\n",
      "Sex                13\n",
      "Purpose             0\n",
      "Hobby               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df3.info())\n",
    "print(\"------\")\n",
    "print(df3.describe()) \n",
    "print(\"~~~~~~\")\n",
    "print(df3.shape)\n",
    "print(\"**********\")\n",
    "print(df3.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c31ff74c-cbf4-443d-bdf2-f5f757d6c73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LP001002'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicate rows\n",
    "dup = df3.duplicated(keep='first')   # Find duplicate rows in the DataFrame 'df' based on all columns, keeping the first occurrence.\n",
    "dropped = df3.loc[dup]   # DataFrame 'dropped' containing only the duplicated rows.\n",
    "dropped['UID'].unique()[0]    # Extract the unique identifier ('UID') of the duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0efc6897-d3aa-4c19-9e18-f1a62559d678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>Marital_status</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Is_graduate</th>\n",
       "      <th>Income</th>\n",
       "      <th>Loan_amount</th>\n",
       "      <th>Term_months</th>\n",
       "      <th>Credit_score</th>\n",
       "      <th>approval_status</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Hobby</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>45848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Education</td>\n",
       "      <td>Reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>45848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Education</td>\n",
       "      <td>Reading</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        UID Marital_status  Dependents Is_graduate  Income  Loan_amount  \\\n",
       "0  LP001002             NO         0.0    Graduate   45848          NaN   \n",
       "1  LP001002             NO         0.0    Graduate   45848          NaN   \n",
       "\n",
       "   Term_months  Credit_score  approval_status   Age   Sex    Purpose    Hobby  \n",
       "0        360.0           1.0                0  40.0  Male  Education  Reading  \n",
       "1        360.0           1.0                0  40.0  Male  Education  Reading  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.loc[df3['UID'].isin(dropped['UID'].unique())]   # Filter the original DataFrame to show only rows with the same 'UID' as the duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1528df61-2396-4b0b-86e4-e73cb771b103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 13)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.drop_duplicates(inplace=True)  # drop duplicate rows from the original DataFrame\n",
    "df3.shape  # shape of the DataFrame after dropping duplicates (1 duplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3f267df2-8563-4bc0-86ad-29d124fdf361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LP002872'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup2 = df3.duplicated(subset=['UID'], keep='first')    # Find duplicate rows in the DataFrame 'df' based on 'UID', keeping the first occurrence.\n",
    "dropped2 = df3.loc[dup2]\n",
    "dropped2['UID'].unique()[0]   # Extract the unique identifier ('UID') of the duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4336ac1b-fa75-4a27-b8a1-97ffa1cf5689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>Marital_status</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Is_graduate</th>\n",
       "      <th>Income</th>\n",
       "      <th>Loan_amount</th>\n",
       "      <th>Term_months</th>\n",
       "      <th>Credit_score</th>\n",
       "      <th>approval_status</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Hobby</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>LP002872</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>45672</td>\n",
       "      <td>136.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wedding</td>\n",
       "      <td>Watching Movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>LP002872</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>32297</td>\n",
       "      <td>110.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Wedding</td>\n",
       "      <td>Watching Movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>LP002872</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41090</td>\n",
       "      <td>107.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Wedding</td>\n",
       "      <td>Watching Movie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          UID Marital_status  Dependents Is_graduate  Income  Loan_amount  \\\n",
       "577  LP002872            Yes         0.0    Graduate   45672        136.0   \n",
       "578  LP002872             No         0.0    Graduate   32297        110.0   \n",
       "579  LP002872            Yes         1.0         NaN   41090        107.0   \n",
       "\n",
       "     Term_months  Credit_score  approval_status   Age   Sex  Purpose  \\\n",
       "577        360.0           0.0                1  33.0   NaN  Wedding   \n",
       "578        360.0           1.0                0  23.0  Male  Wedding   \n",
       "579        360.0           1.0                0  47.0  Male  Wedding   \n",
       "\n",
       "              Hobby  \n",
       "577  Watching Movie  \n",
       "578  Watching Movie  \n",
       "579  Watching Movie  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.loc[df3['UID'].isin(dropped2['UID'].unique())]    # Filter the original DataFrame to show only rows with the same 'UID' as the duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b1effef0-f48c-4abe-9fcf-68d51fd638f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(612, 13)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.drop_duplicates('UID', keep='first', inplace=True)  # drop duplicates('Column', keep='first')\n",
    "df3.shape    # shape of the DataFrame after dropping duplicates (2 duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2b61657b-af02-42d7-8d12-c2aab3e14bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Marital_status\n",
       "Yes    273\n",
       "No     155\n",
       "YES    112\n",
       "NO      70\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data standardization\n",
    "df3['Marital_status'].value_counts() # counts the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c9ebe11f-86de-4281-b15f-0f5857dd351c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Marital_status\n",
       "YES    385\n",
       "NO     225\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['Marital_status'] = df3['Marital_status'].str.upper()   # converts all the values to Uppercase\n",
    "df3['Marital_status'].value_counts()   # counts the occurrences of 'YES' and 'NO' after case conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "052ac41a-7152-434d-b1ba-7b99114367dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex\n",
       "Male      460\n",
       "Female    107\n",
       "M          18\n",
       "F          14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['Sex'].value_counts()    # counts the occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a3079be4-7fc2-4df1-84d4-342c1bc214c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex\n",
       "Male      478\n",
       "Female    121\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We replace 'M' -> 'Male' and 'F' -> 'Female'\n",
    "df3['Sex'] = df3['Sex'].replace({'M' : 'Male', 'F' : 'Female'})    # replace({old_value : new_value}) dict(old_value=new_value)\n",
    "df3['Sex'].value_counts()    # counts the occurrences of 'Male' and 'Female' after replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01c42831-f5ac-4b1b-8a6b-7546ee38e1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Dependents        Income  Loan_amount  Term_months  Credit_score  \\\n",
      "count  600.000000  6.150000e+02   592.000000   601.000000    565.000000   \n",
      "mean     0.761667  1.896745e+05   146.412162   342.029950      0.842478   \n",
      "std      1.014847  4.031317e+06    85.587325    65.070263      0.364615   \n",
      "min      0.000000  5.001000e+03     9.000000    12.000000      0.000000   \n",
      "25%      0.000000  1.613200e+04   100.000000   360.000000      1.000000   \n",
      "50%      0.000000  2.628700e+04   128.000000   360.000000      1.000000   \n",
      "75%      2.000000  3.847700e+04   168.000000   360.000000      1.000000   \n",
      "max      3.000000  1.000000e+08   700.000000   480.000000      1.000000   \n",
      "\n",
      "       approval_status         Age  \n",
      "count       615.000000  609.000000  \n",
      "mean          0.487805   38.067323  \n",
      "std           0.500258   10.471628  \n",
      "min           0.000000  -12.000000  \n",
      "25%           0.000000   29.000000  \n",
      "50%           0.000000   37.000000  \n",
      "75%           1.000000   47.000000  \n",
      "max           1.000000   55.000000  \n",
      "~~~~~~~~~~~~~~~~~~\n",
      "615\n",
      "~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UID                 0\n",
       "Marital_status      2\n",
       "Dependents         15\n",
       "Is_graduate         2\n",
       "Income              0\n",
       "Loan_amount        23\n",
       "Term_months        14\n",
       "Credit_score       50\n",
       "approval_status     0\n",
       "Age                 6\n",
       "Sex                13\n",
       "Purpose             0\n",
       "Hobby               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have familiarized ourselves with the data, maybe we can tackle inaccurate records? \n",
    "print(df3.describe())   # Checking for Incorrect Records\n",
    "print(\"~~~~~~~~~~~~~~~~~~\")\n",
    "print(df3.shape[0])   # No of rows\n",
    "print(\"~~~~~~~~~~~~~~~~~~\")\n",
    "df3.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea8a74-ae8e-4e7c-aecc-da0b1606317b",
   "metadata": {},
   "source": [
    "There are two suspicious things going on with the Age column that speaks to both accuracy and missing data. Who is -12 years old? How is that possible? Plus there are 6 Ages that we don't have at all. \n",
    "\n",
    "The strategy for Age might be to replace the missing data and the inaccurate date (let's say any age under 10) with the mean value of the other values in that column. This strategy is worked below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "10228892-2b27-4e25-8c44-3c72284d12a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.0\n"
     ]
    }
   ],
   "source": [
    "# Why is there a minimum age tht is -12? Who is -12 years old? We will need to remove this: \n",
    "print(df3['Age'].min())   # Incorrect Minimum age\n",
    "# we will replace all ages that are < 10 with a missing value and then we will address missing values in the next cell\n",
    "df3.loc[df3[\"Age\"]<10,\"Age\"]=df3[\"Age\"].mean()\n",
    "#check to see the min of the Age column\n",
    "df3['Age'].min()  \n",
    "# That's better! Let's replace the 6 missing values with the mean value of the column, too. \n",
    "#df3['Age'].fillna(df3['Age'].mean(),inplace=True)\n",
    "df3[\"Age\"] = df3[\"Age\"].fillna(df3[\"Age\"].mean())\n",
    "# You can also use the SimpleImputer function from sklearn\n",
    "# as we used in the df1, df2 examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c96752c7-d1eb-4c54-94c5-e062d574a807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      40.0\n",
      "1      40.0\n",
      "2      22.0\n",
      "3      27.0\n",
      "4      36.0\n",
      "       ... \n",
      "610    55.0\n",
      "611    47.0\n",
      "612    27.0\n",
      "613    47.0\n",
      "614    42.0\n",
      "Name: Age, Length: 615, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df3[\"Age\"])\n",
    "# have we replaced all the missing elements in the Age column with the mean?\n",
    "df3[\"Age\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "edee83dd-e1df-476c-a868-deb3620b4e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(615, 13)\n",
      "--------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UID                 0\n",
       "Marital_status      2\n",
       "Dependents         15\n",
       "Is_graduate         2\n",
       "Income              0\n",
       "Loan_amount        23\n",
       "Term_months        14\n",
       "Credit_score       50\n",
       "approval_status     0\n",
       "Age                 0\n",
       "Sex                13\n",
       "Purpose             0\n",
       "Hobby               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handle missing values: \n",
    "print(df3.shape)\n",
    "print(\"--------------\")\n",
    "df3.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa66fb70-82de-4339-92a1-e28931a24e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UID                 0\n",
       "Marital_status      2\n",
       "Dependents         15\n",
       "Is_graduate         2\n",
       "Income              0\n",
       "Loan_amount        23\n",
       "Term_months        14\n",
       "Credit_score       50\n",
       "approval_status     0\n",
       "Age                 0\n",
       "Sex                13\n",
       "Purpose             0\n",
       "Hobby               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace missing (null or NaN) values with mean of that column\n",
    "df3['Loan_amount'].fillna(df3['Term_months'].mean())\n",
    "#df3.isnull().sum()\n",
    "df3['Term_months'].fillna(df3['Term_months'].mean())\n",
    "print(\"*****************\")\n",
    "df3.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b3c701f9-1236-4007-b367-86c6036eea74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UID                0\n",
      "Marital_status     0\n",
      "Dependents         0\n",
      "Is_graduate        0\n",
      "Income             0\n",
      "Loan_amount        0\n",
      "Term_months        0\n",
      "Credit_score       0\n",
      "approval_status    0\n",
      "Age                0\n",
      "Sex                0\n",
      "Purpose            0\n",
      "Hobby              0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(503, 13)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we might decide that some of the columns contain irrelevant information\n",
    "# so we can just drop all the rows with missing values\n",
    "df3.dropna(inplace=True)   # We drop the records with missing values\n",
    "print(df3.isnull().sum())   # count missing values\n",
    "df3.shape # we can see how many rows we have now dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b611877f-8681-45a4-81e0-e008855645d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSTenv",
   "language": "python",
   "name": "dstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
